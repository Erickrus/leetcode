{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XC6PidnDHP3M",
        "UmFHvvM1GDUu",
        "BAK6POjGHCxH",
        "Fpq3wLN3I_RW",
        "FGfH36ObPGxx"
      ],
      "authorship_tag": "ABX9TyPSgxVzLt6ksSnIhHt40mAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erickrus/leetcode/blob/master/StableDiffusionPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion Models\n",
        "This is an easy-to-understand implementation of diffusion models within 100 lines of code. Different from other implementations, this code doesn't use the lower-bound formulation for sampling and strictly follows Algorithm 1 from the [DDPM](https://arxiv.org/pdf/2006.11239.pdf) paper, which makes it extremely short and easy to follow. There is only one implementation: `unconditional` in this notebook. Below you can find two explanation videos for the theory behind diffusion models and the implementation.\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=HoKDTa5jHvg\">\n",
        "   <img alt=\"Qries\" src=\"https://user-images.githubusercontent.com/61938694/191407922-f613759e-4bea-4ac9-9135-d053a6312421.jpg\"\n",
        "   width=\"300\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=TBCRlnwJtZU\">\n",
        "   <img alt=\"Qries\" src=\"https://user-images.githubusercontent.com/61938694/191407849-6d0376c7-05b2-43cd-a75c-1280b0e33af1.png\"\n",
        "   width=\"300\">\n",
        "</a>\n",
        "\n",
        "<hr>\n"
      ],
      "metadata": {
        "id": "N04LD306wMEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prepare CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "XC6PidnDHP3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download CIFAR-10 dataset\n",
        "%cd /content\n",
        "!rm -Rf /content/ddpm\n",
        "!rm -Rf /content/CIFAR-10-images\n",
        "!git clone https://github.com/YoongiKim/CIFAR-10-images\n",
        "!mkdir /content/ddpm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3VenSfKqL1D",
        "outputId": "ac6a1eeb-3b82-4ef6-9fea-cf5dbb8b28a1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'CIFAR-10-images'...\n",
            "remote: Enumerating objects: 60027, done.\u001b[K\n",
            "remote: Total 60027 (delta 0), reused 0 (delta 0), pack-reused 60027\u001b[K\n",
            "Receiving objects: 100% (60027/60027), 19.94 MiB | 17.25 MiB/s, done.\n",
            "Resolving deltas: 100% (59990/59990), done.\n",
            "Checking out files: 100% (60001/60001), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title shink dataset size\n",
        "#@markdown Image to keep per category\n",
        "imageToKeep = 80 #@param {\"type\":\"integer\"}\n",
        "\n",
        "print(\"It takes a while, and please wait ...\")\n",
        "import glob, os\n",
        "for filename in glob.glob(\"/content/CIFAR-10-images/test/**/*.jpg\"):\n",
        "  shortFilename = os.path.basename(filename).replace(\".jpg\",\"\")\n",
        "  fileId = int(shortFilename)\n",
        "  if fileId >= imageToKeep:\n",
        "    os.system(\"rm %s\" % filename)\n",
        "print(len(glob.glob(\"/content/CIFAR-10-images/test/**/*.jpg\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf_puzcw06ci",
        "outputId": "812d1366-9105-435e-9045-ed980e59ff9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It takes a while, and please wait ...\n",
            "800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### modules.py"
      ],
      "metadata": {
        "id": "UmFHvvM1GDUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SelfAttention\n",
        "#@markdown self attention\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, channels, size):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.size = size\n",
        "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
        "        self.ln = nn.LayerNorm([channels])\n",
        "        self.ff_self = nn.Sequential(\n",
        "            nn.LayerNorm([channels]),\n",
        "            nn.Linear(channels, channels),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(channels, channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
        "        x_ln = self.ln(x)\n",
        "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
        "        attention_value = attention_value + x\n",
        "        attention_value = self.ff_self(attention_value) + attention_value\n",
        "        return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)\n"
      ],
      "metadata": {
        "id": "sFJsW_EVw2hR",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DoubleConv\n",
        "#@markdown double convolution\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
        "        super().__init__()\n",
        "        self.residual = residual\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(1, mid_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(1, out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.residual:\n",
        "            return F.gelu(x + self.double_conv(x))\n",
        "        else:\n",
        "            return self.double_conv(x)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "13urmSLyGR7G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Down\n",
        "#@markdown downsample process\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, in_channels, residual=True),\n",
        "            DoubleConv(in_channels, out_channels),\n",
        "        )\n",
        "\n",
        "        self.emb_layer = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(\n",
        "                emb_dim,\n",
        "                out_channels\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.maxpool_conv(x)\n",
        "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
        "        return x + emb\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CUghivY4Gb1E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Up\n",
        "#@markdown upsample process\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        self.conv = nn.Sequential(\n",
        "            DoubleConv(in_channels, in_channels, residual=True),\n",
        "            DoubleConv(in_channels, out_channels, in_channels // 2),\n",
        "        )\n",
        "\n",
        "        self.emb_layer = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(\n",
        "                emb_dim,\n",
        "                out_channels\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, skip_x, t):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([skip_x, x], dim=1)\n",
        "        x = self.conv(x)\n",
        "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
        "        return x + emb\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2uH4s-bBGgbH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title UNet\n",
        "#@markdown UNet is $\\epsilon_{\\theta}(x_t,t)$\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, c_in=3, c_out=3, time_dim=256, device=\"cuda\"):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.time_dim = time_dim\n",
        "        self.inc = DoubleConv(c_in, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.sa1 = SelfAttention(128, 32)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.sa2 = SelfAttention(256, 16)\n",
        "        self.down3 = Down(256, 256)\n",
        "        self.sa3 = SelfAttention(256, 8)\n",
        "\n",
        "        self.bot1 = DoubleConv(256, 512)\n",
        "        self.bot2 = DoubleConv(512, 512)\n",
        "        self.bot3 = DoubleConv(512, 256)\n",
        "\n",
        "        self.up1 = Up(512, 128)\n",
        "        self.sa4 = SelfAttention(128, 16)\n",
        "        self.up2 = Up(256, 64)\n",
        "        self.sa5 = SelfAttention(64, 32)\n",
        "        self.up3 = Up(128, 64)\n",
        "        self.sa6 = SelfAttention(64, 64)\n",
        "        self.outc = nn.Conv2d(64, c_out, kernel_size=1)\n",
        "\n",
        "    def pos_encoding(self, t, channels):\n",
        "        inv_freq = 1.0 / (\n",
        "            10000\n",
        "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
        "        )\n",
        "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
        "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
        "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
        "        return pos_enc\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t = t.unsqueeze(-1).type(torch.float)\n",
        "        t = self.pos_encoding(t, self.time_dim)\n",
        "\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1, t)\n",
        "        x2 = self.sa1(x2)\n",
        "        x3 = self.down2(x2, t)\n",
        "        x3 = self.sa2(x3)\n",
        "        x4 = self.down3(x3, t)\n",
        "        x4 = self.sa3(x4)\n",
        "\n",
        "        x4 = self.bot1(x4)\n",
        "        x4 = self.bot2(x4)\n",
        "        x4 = self.bot3(x4)\n",
        "\n",
        "        x = self.up1(x4, x3, t)\n",
        "        x = self.sa4(x)\n",
        "        x = self.up2(x, x2, t)\n",
        "        x = self.sa5(x)\n",
        "        x = self.up3(x, x1, t)\n",
        "        x = self.sa6(x)\n",
        "        output = self.outc(x)\n",
        "        return output"
      ],
      "metadata": {
        "cellView": "form",
        "id": "txX02reiGmd3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###utils.py"
      ],
      "metadata": {
        "id": "BAK6POjGHCxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title utils.py\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#@markdown plot_images\n",
        "def plot_images(images):\n",
        "    plt.figure(figsize=(32, 32))\n",
        "    plt.imshow(torch.cat([\n",
        "        torch.cat([i for i in images.cpu()], dim=-1),\n",
        "    ], dim=-2).permute(1, 2, 0).cpu())\n",
        "    plt.show()\n",
        "\n",
        "#@markdown save_images\n",
        "def save_images(images, path, **kwargs):\n",
        "    grid = torchvision.utils.make_grid(images, **kwargs)\n",
        "    ndarr = grid.permute(1, 2, 0).to('cpu').numpy()\n",
        "    im = Image.fromarray(ndarr)\n",
        "    im.save(path)\n",
        "    display(im)\n",
        "\n",
        "#@markdown get_data\n",
        "def get_data(args):\n",
        "    transforms = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(80),  # args.image_size + 1/4 *args.image_size\n",
        "        torchvision.transforms.RandomResizedCrop(args.image_size, scale=(0.8, 1.0)),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    dataset = torchvision.datasets.ImageFolder(args.dataset_path, transform=transforms)\n",
        "    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
        "    return dataloader\n",
        "\n",
        "#@markdown setup_logging\n",
        "def setup_logging(run_name):\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    os.makedirs(os.path.join(\"models\", run_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(\"results\", run_name), exist_ok=True)"
      ],
      "metadata": {
        "id": "wueS1Kv3xI5g",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Diffusion Class"
      ],
      "metadata": {
        "id": "Fpq3wLN3I_RW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qj6FQJfIl8eY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Re-parameterization Trick\n",
        "import datetime\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "#import logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "#logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
        "\n",
        "\n",
        "class Diffusion:\n",
        "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n",
        "        self.noise_steps = noise_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.img_size = img_size\n",
        "        self.device = device\n",
        "        #@markdown Linear beta model\n",
        "        self.beta = self.prepare_noise_schedule().to(device)\n",
        "        #@markdown **Reparameterization Trick**\n",
        "        #@markdown\n",
        "        #@markdown $\\alpha_t=1-\\beta_t$\n",
        "        self.alpha = 1. - self.beta\n",
        "        #@markdown $\\bar\\alpha=\\displaystyle\\prod^{t}_{s=1}\\alpha_s$, accumulative product of $\\alpha$\n",
        "        #@markdown\n",
        "        #@markdown *Notes: In the code, $\\bar\\alpha$ is called as alpha_hat, this is not correct*\n",
        "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title prepare_noise_schedule, noise_images, sample_timesteps\n",
        "\n",
        "\n",
        "#@markdown `prepare_noise_schedule()` Linear Schedule\n",
        "#@markdown\n",
        "#@markdown > simply using linspace from $\\beta_{start}$ to $\\beta_{end}$\n",
        "def prepare_noise_schedule(self):\n",
        "    #@markdown > If you want to change it to cosine schedule like what OpenAI does, \n",
        "    #@markdown > it should be easy to do it here\n",
        "    return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
        "\n",
        "#@markdown `noise_images(x, t)`\n",
        "def noise_images(self, x, t):\n",
        "    #@markdown > a) samples $\\epsilon$ from $N(0,I)$\n",
        "    e = torch.randn_like(x)\n",
        "    #@markdown > b) forward process $q(x_t|x_{t-1})$: calculates $x_t=\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\epsilon$\n",
        "    sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
        "    sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
        "    \n",
        "    return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * e, e\n",
        "\n",
        "#@markdown `sample_timesteps(n)` is to $T \\sim Uniform({1,...,T})$\n",
        "def sample_timesteps(self, n):\n",
        "    return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
        "\n",
        "\n",
        "\n",
        "Diffusion.prepare_noise_schedule = prepare_noise_schedule\n",
        "Diffusion.noise_images = noise_images\n",
        "Diffusion.sample_timesteps = sample_timesteps\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mBXT0fAiH5M1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Algorithm 2 Sampling\n",
        "\n",
        "def sample(self, model, n):\n",
        "    print(datetime.datetime.now(), f\"sample {n} new images....\")\n",
        "    #@markdown **Algorithm 2 Sampling**        \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        #@markdown 1: $x_T \\sim N(0,I)$\n",
        "        #@markdown\n",
        "        #@markdown the shape is exactly the same as image\n",
        "        x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n",
        "        #@markdown 2: for $t=T,...,1$ do\n",
        "        #@markdown\n",
        "        #@markdown that is to execute T times the backward process $p(x_{t-1}|x_t)$ \n",
        "        for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
        "            #@markdown > 3: $z \\sim N(0,I)$ if $t>1$, else $z=0$\n",
        "            t = (torch.ones(n) * i).long().to(self.device)\n",
        "            #@markdown > 4: $x_{t-1}=\\frac{1}{\\sqrt{\\alpha_t}}(x_t-\\frac{1-\\alpha_t}{\\sqrt{1-\\alpha_t}}\\epsilon_{\\theta}(x_t,t))$\n",
        "            #@markdown \n",
        "            #@markdown > `model(x, t)` or `predicted_noise` is acutally the $\\epsilon_{\\theta}(x_t,t)$\n",
        "            predicted_noise = model(x, t)\n",
        "            alpha = self.alpha[t][:, None, None, None]\n",
        "            alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
        "            beta = self.beta[t][:, None, None, None]\n",
        "            if i > 1:\n",
        "                noise = torch.randn_like(x)\n",
        "            else:\n",
        "                noise = torch.zeros_like(x)\n",
        "            \n",
        "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
        "            #@markdown 5: end for\n",
        "    model.train()\n",
        "    #@markdown 6: return $x_0$\n",
        "    x = (x.clamp(-1, 1) + 1) / 2\n",
        "    x = (x * 255).type(torch.uint8)\n",
        "    return x\n",
        "\n",
        "Diffusion.sample = sample"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Fq3a1kL3IDY-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Algorithm 1 Training\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "import logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "def train(args):\n",
        "    setup_logging(args.run_name)\n",
        "    device = args.device\n",
        "    dataloader = get_data(args)\n",
        "    model = UNet().to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
        "    mse = nn.MSELoss()\n",
        "    diffusion = Diffusion(img_size=args.image_size, device=device)\n",
        "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
        "    l = len(dataloader)\n",
        "    #@markdown **Algorithm 1 Training**\n",
        "    #@markdown     \n",
        "    #@markdown 1: repeat\n",
        "    for epoch in range(args.epochs):\n",
        "        #IPython.display.clear_output(wait=True)\n",
        "        print(datetime.datetime.now(), f\"epoch: {epoch}:\")\n",
        "        # load data loops and augument a little bit\n",
        "        print(datetime.datetime.now(), \"train\")\n",
        "        pbar = tqdm(dataloader)\n",
        "        losses = []\n",
        "        for i, (images, _) in enumerate(pbar):\n",
        "            #@markdown > 2: $x_0 \\sim q(x_0)$\n",
        "            #@markdown forward process\n",
        "            images = images.to(device)            \n",
        "            #@markdown > 3: $T \\sim Uniform({1,...,T})$ \n",
        "            t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
        "            \n",
        "            #@markdown > 4: $\\epsilon \\sim N(0,I)$\n",
        "            #@markdown > \n",
        "            #@markdown > `noise_images(images, t)` does 2 things here:\n",
        "            #@markdown >> \n",
        "            #@markdown >> a) samples $\\epsilon$ from $N(0,I)$\n",
        "            #@markdown >> \n",
        "            #@markdown >> b) forward process $q(x_t|x_{t-1})$: calculates $x_t=\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\epsilon$\n",
        "            x_t, noise = diffusion.noise_images(images, t)\n",
        "\n",
        "            #@markdown > 5: Take gradient descent step on\n",
        "            #@markdown \n",
        "            #@markdown >> `predicted_noise = `$\\epsilon_{\\theta}(\\sqrt{\\bar\\alpha_t}x_0-\\sqrt{1-\\bar\\alpha_t}\\epsilon,t)$\n",
        "            predicted_noise = model(x_t, t)\n",
        "\n",
        "            #@markdown >> $\\nabla_{\\theta}||\\epsilon - \\epsilon_{\\theta}(\\sqrt{\\bar\\alpha_t}x_0-\\sqrt{1-\\bar\\alpha_t}\\epsilon,t) ||^2 $\n",
        "            loss = mse(noise, predicted_noise)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_postfix(MSE=loss.item())\n",
        "            losses.append(loss.item())\n",
        "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
        "        print(datetime.datetime.now(), 'loss %.8f' % np.array(losses).mean())\n",
        "        \n",
        "        # sample process is extremely time consuming, only execute once every 10 epochs\n",
        "        if not (epoch>0 and epoch%10==0): \n",
        "            continue\n",
        "        #**algorithm 2** is called when predicting\n",
        "        sampled_images = diffusion.sample(model, n=images.shape[0])\n",
        "        save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
        "        torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))\n",
        "    #@markdown 6: until converged\n",
        "    #@markdown \n",
        "    #@markdown we dont have this step here\n"
      ],
      "metadata": {
        "id": "hSzWYsCAxSDt",
        "cellView": "form"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "FGfH36ObPGxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title execute the training process\n",
        "%cd /content/ddpm\n",
        "\n",
        "def launch_train():\n",
        "    import argparse\n",
        "    #parser = argparse.ArgumentParser()\n",
        "    #args = parser.parse_args()\n",
        "    class Args():\n",
        "      def __init__(self):\n",
        "        self.run_name = \"DDPM_Uncondtional\"\n",
        "        self.epochs = 100\n",
        "        self.batch_size = 4\n",
        "        self.image_size = 64\n",
        "        self.dataset_path = r\"/content/CIFAR-10-images/test\"\n",
        "        self.device = \"cuda\"\n",
        "        self.lr = 3e-4\n",
        "    train(Args())\n",
        "\n",
        "launch_train()\n"
      ],
      "metadata": {
        "id": "-k7wG7vVxUPG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55d7daa2-03fd-4896-c084-b466b189ad6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ddpm\n",
            "2022-10-06 07:38:04.461473 epoch: 0:\n",
            "2022-10-06 07:38:04.461603 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:35<00:00,  5.68it/s, MSE=0.0747]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:38:39.668905 loss 0.19626181\n",
            "2022-10-06 07:38:39.669128 epoch: 1:\n",
            "2022-10-06 07:38:39.669166 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:33<00:00,  6.01it/s, MSE=0.0446]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:39:12.958104 loss 0.06084056\n",
            "2022-10-06 07:39:12.958913 epoch: 2:\n",
            "2022-10-06 07:39:12.958972 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:33<00:00,  5.98it/s, MSE=0.0287]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:39:46.405996 loss 0.04395297\n",
            "2022-10-06 07:39:46.406154 epoch: 3:\n",
            "2022-10-06 07:39:46.406207 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:33<00:00,  5.94it/s, MSE=0.0163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:40:20.077543 loss 0.03679429\n",
            "2022-10-06 07:40:20.078077 epoch: 4:\n",
            "2022-10-06 07:40:20.078122 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:33<00:00,  5.90it/s, MSE=0.0203]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:40:53.993574 loss 0.02845562\n",
            "2022-10-06 07:40:53.995947 epoch: 5:\n",
            "2022-10-06 07:40:53.996004 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.84it/s, MSE=0.0121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:41:28.240373 loss 0.02897122\n",
            "2022-10-06 07:41:28.240586 epoch: 6:\n",
            "2022-10-06 07:41:28.240623 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.87it/s, MSE=0.0326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:42:02.319517 loss 0.02340002\n",
            "2022-10-06 07:42:02.319702 epoch: 7:\n",
            "2022-10-06 07:42:02.319740 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.86it/s, MSE=0.0237]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:42:36.447761 loss 0.02328044\n",
            "2022-10-06 07:42:36.450442 epoch: 8:\n",
            "2022-10-06 07:42:36.450505 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.84it/s, MSE=0.0307]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:43:10.722552 loss 0.02211619\n",
            "2022-10-06 07:43:10.722743 epoch: 9:\n",
            "2022-10-06 07:43:10.722781 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.82it/s, MSE=0.0856]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:43:45.093306 loss 0.02410219\n",
            "2022-10-06 07:43:45.093508 epoch: 10:\n",
            "2022-10-06 07:43:45.093546 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.84it/s, MSE=0.0296]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:44:19.356535 loss 0.02036360\n",
            "2022-10-06 07:44:19.356742 sample 4 new images....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "999it [00:55, 18.01it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=266x68 at 0x7FAB3CEE1D90>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:45:15.045708 epoch: 11:\n",
            "2022-10-06 07:45:15.047157 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.79it/s, MSE=0.00664]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:45:49.596676 loss 0.01782811\n",
            "2022-10-06 07:45:49.596858 epoch: 12:\n",
            "2022-10-06 07:45:49.596891 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.84it/s, MSE=0.00982]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:46:23.852719 loss 0.01902352\n",
            "2022-10-06 07:46:23.852898 epoch: 13:\n",
            "2022-10-06 07:46:23.852933 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:34<00:00,  5.84it/s, MSE=0.0256]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-06 07:46:58.084033 loss 0.01802868\n",
            "2022-10-06 07:46:58.084237 epoch: 14:\n",
            "2022-10-06 07:46:58.084274 train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 174/200 [00:29<00:04,  5.72it/s, MSE=0.00636]"
          ]
        }
      ]
    }
  ]
}